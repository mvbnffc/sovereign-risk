{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86eb7f50-46f7-41d0-9229-2cb4aa29df42",
   "metadata": {},
   "source": [
    "### Presimulation Notebook # 3 - DIGNAD Macroeconomic Model pre-simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b2327-f75b-4401-8255-6d7a06a2fc2b",
   "metadata": {},
   "source": [
    "Because each DIGNAD run takes ~1 min to complete, large Monte-Carlo simulations aren't really feasible. This notebook runs DIGNAD presimulations over a realistic parameter space to produce a dataset that can easily be incorporated into later Monte Carlo runs and significantly speed up those simulations. \n",
    "\n",
    "In this notebook, we run a flood risk simulation to understand get a range of possible losses. Using these results we create a parameter grid over which we will run the DIGNAD simulations. For an adaptation and no adaptation scenario we run ~1000 DIGNAD simulations (this takes ~16 hours per run) and save results to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c469127e-7396-4df3-8aaa-fb7d46f0cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import live code changes in\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sovereign.flood import build_basin_curves, BasinLossCurve, risk_data_future_shift, run_simulation, extract_sectoral_losses\n",
    "from sovereign.macroeconomic import run_flood_sim_for_macro, create_dignad_parameter_grid, prepare_DIGNAD, run_DIGNAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cb03f-9bf3-4e30-9b3a-72eda3cf17c8",
   "metadata": {},
   "source": [
    "##### 1. User config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f16631f-9456-4519-8e1d-a39cfad19e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_aep = 0.01 # 100-year flood protection (adaptation scenario)\n",
    "n_years = 100000 # number of years to simulate (wouldn't normally do 100K but want to get worst-case)\n",
    "# Future climate parameters (we want max risk so choose latest epoch, highest emission scenario and q95)\n",
    "future_hydro = 'jules-w2'\n",
    "future_epoch = 2070\n",
    "future_scenario = 'ssp585'\n",
    "future_stat = 'q95'\n",
    "# Macroeconomic data (for preparing DIGNAD simulation)\n",
    "Thai_GDP = 496e9 # 2022 numbers in USD\n",
    "# National GVA figures from DOSE\n",
    "agr_GVA = 42880325598\n",
    "man_GVA = 162659433017\n",
    "ser_GVA = 316647741231\n",
    "# Disaggregate output losses (what share of each sector are tradable)\n",
    "TRADABLE_SHARES = {\n",
    "    \"Agriculture\": 1.0,\n",
    "    \"Manufacturing\": 0.7,\n",
    "    \"Service\": 0.5,\n",
    "}\n",
    "# DIGNAD parameters\n",
    "n_dignad_simulations = 1000 # takes ~ 16 hours but gives good coverage of parameter space\n",
    "sim_start_year = 2022\n",
    "nat_disaster_year = 2027 # disaster happens n+5 years after start of simulation\n",
    "recovery_period = 3 # recover time in DIGNAD\n",
    "adaptation_cost = 21.97 # billion (can find the cost of the adaptation scenario in the preparation/flood_protection.ipynb notebook)\n",
    "reconstruction_efficiency = 0 # non-adjustable parameter\n",
    "public_debt_premium = 0 # non-adjustable parameter\n",
    "gdp_avg_years = 5 # we are intereseted in calculating average GDP impact over this period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be7e62-0b19-45cf-81ab-2800a546dca8",
   "metadata": {},
   "source": [
    "##### 2. Set filepaths and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f68b88d-8bd8-460c-81d3-d9c2c10cda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent.parent # find project root\n",
    "THA_calibration_path = os.path.join(root, \"inputs\", \"macro\", \"THA_2022_calibration_final.csv\") # DIGNAD calibration\n",
    "risk_basin_path = os.path.join(root, 'outputs', 'flood', 'risk', 'basins', 'risk_basins.csv')\n",
    "copula_path = os.path.join(root, 'outputs', 'flood', 'dependence', 'copulas')\n",
    "copula_random_numbers = pd.read_parquet(os.path.join(copula_path, \"copula_random_numbers.gzip\"))\n",
    "dignad_output_noadapt = os.path.join(root, 'outputs', 'macro', f'DIGNAD_presim_n{n_dignad_simulations}_noadapt.csv')\n",
    "dignad_output_adapt = os.path.join(root, 'outputs', 'macro', f'DIGNAD_presim_n{n_dignad_simulations}_adapt.csv')\n",
    "risk_data = pd.read_csv(risk_basin_path)\n",
    "future_rp_shifts = pd.read_csv(os.path.join(root, 'outputs', 'flood', 'future', 'basin_rp_shifts.csv'))\n",
    "# Fix the risk data\n",
    "# Drop first \"unnamed column\"\n",
    "risk_data = risk_data.iloc[:, 1:]\n",
    "# Add AEP column\n",
    "risk_data['AEP'] = 1 / risk_data['RP']\n",
    "# Add a column converting current prorection level into AEP\n",
    "risk_data['Pr_L_AEP'] = np.where(risk_data['Pr_L'] == 0, 0, 1 / risk_data['Pr_L']) # using numpy where avoids zero division errors\n",
    "risk_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6736650-c833-456a-84e1-e8b35688be12",
   "metadata": {},
   "source": [
    "##### 3. Prepare data for risk assessment (future climate adjustment and loss curve creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969b3032-3d4e-4555-99f4-35fb9b0d3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust future risk data\n",
    "future_risk_data = risk_data_future_shift(risk_data, future_rp_shifts, future_hydro, future_scenario, future_epoch, future_stat, degrade_protection=True)\n",
    "# Build basin loss probability curves\n",
    "baseline_curves: dict[int, BasinLossCurve] = build_basin_curves(risk_data)\n",
    "future_curves: dict[int, BasinLossCurve] = build_basin_curves(future_risk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd33eb2-d5a7-42ce-9d36-62a8e997e4f7",
   "metadata": {},
   "source": [
    "##### 4. Run flood risk assessment (outputting DIGNAD inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47e19a4-9974-44cc-a5e9-d3dc4a44f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100000/100000 [09:35<00:00, 173.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 100000/100000 [11:06<00:00, 150.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Baseline (no climate change)\n",
    "baseline_current_df, baseline_adapted_df = run_flood_sim_for_macro(\n",
    "    baseline_curves, adaptation_aep, n_years, copula_random_numbers,\n",
    "    agr_GVA, man_GVA, ser_GVA, TRADABLE_SHARES, Thai_GDP\n",
    ")\n",
    "# Future (with climate change)\n",
    "future_current_df, future_adapted_df = run_flood_sim_for_macro(\n",
    "    future_curves, adaptation_aep, n_years, copula_random_numbers,\n",
    "    agr_GVA, man_GVA, ser_GVA, TRADABLE_SHARES, Thai_GDP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0c8933-ab79-437a-a6fc-ab4620602c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all scenarios into one DataFrame (only need to use no adaptation, as losses will be higher)\n",
    "flood_combined = pd.concat([baseline_current_df, future_current_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca169e4-f9d7-488a-aa73-614a1c64d4bb",
   "metadata": {},
   "source": [
    "##### 5. Create DIGNAD parameter grid\n",
    "In this step we create a parameter grid of DIGNAD shock combinations from our flood simulation results. We do this by sampling the joint parameter space using either k-means cluster centres, stratified sampling by event severity, KDE-based resampling, or a combination of all three. We also append tail events to ensure we are capturing edge cases in parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fe2da6-0b9c-48ee-bb4a-13ff361781f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating DIGNAD parameter grid using 'combined' method...\n",
      "Target samples: 20\n",
      "\n",
      "Final parameter grid:\n",
      "  Grid size: 42 unique combinations\n",
      "  Parameter ranges:\n",
      "    dY_T: [0.000, 0.251]\n",
      "    dY_N: [0.000, 0.284]\n",
      "    dK_priv: [0.000, 0.467]\n",
      "    dK_pub: [0.000, 0.168]\n"
     ]
    }
   ],
   "source": [
    "param_grid = create_dignad_parameter_grid(\n",
    "    flood_combined,\n",
    "    n_samples=20,\n",
    "    method='combined',  # Uses multiple sampling methods\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2acf03-af7b-408d-ae99-ed2abfae947f",
   "metadata": {},
   "source": [
    "##### 6. Run DIGNAD pre-simulation (no adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d082ca-ceb3-4e34-b39f-e0189cb02011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating DIGNAD (no adaptation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DIGNAD precomputation:  17%|████████▋                                           | 7/42 [06:42<32:09, 55.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB script not executed succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DIGNAD precomputation: 100%|███████████████████████████████████████████████████| 42/42 [39:20<00:00, 56.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calibrate DIGNAD (baseline = no adaptation)\n",
    "print('Calibrating DIGNAD (no adaptation)')\n",
    "prepare_DIGNAD(THA_calibration_path, adaptation_cost=0, root_dir=root)\n",
    "\n",
    "# Run pre-compuataion\n",
    "results_na = []\n",
    "failure_index_na = []\n",
    "for row in tqdm(param_grid.itertuples(index=False), total=len(param_grid), desc=\"Running DIGNAD precomputation\"):\n",
    "    # Extract shock paramaters\n",
    "    index = row.grid_index\n",
    "    tradable_impact = row.tradable_impact\n",
    "    nontradable_impact = row.nontradable_impact\n",
    "    private_impact = row.private_impact\n",
    "    public_impact = row.public_impact\n",
    "    share_tradable = row.share_tradable\n",
    "    reconstruction_efficiency = row.reconstruction_efficiency\n",
    "    public_debt_premium = row.public_debt_premium\n",
    "\n",
    "    # If shocks are 0 don't run DIGNAD\n",
    "    if tradable_impact == 0 and nontradable_impact == 0 and private_impact == 0 and public_impact == 0:\n",
    "        results_na.append({\n",
    "            \"index\": index,\n",
    "            \"gdp_avg\": 0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Run DIGNAD\n",
    "    gdp_impact, years = run_DIGNAD(sim_start_year, nat_disaster_year, recovery_period, tradable_impact, nontradable_impact,\n",
    "                                    reconstruction_efficiency, public_debt_premium, public_impact, private_impact, share_tradable, root)\n",
    "\n",
    "    if gdp_impact is None:\n",
    "        # Means MatLab failed to execute\n",
    "        failure_index_na.append(index)\n",
    "        gdp_avg = None\n",
    "    else:\n",
    "        t_shock = nat_disaster_year-sim_start_year\n",
    "        gdp_avg = np.mean(gdp_impact[t_shock : t_shock + gdp_avg_years])\n",
    "\n",
    "    results_na.append({\n",
    "        \"index\": index,\n",
    "        \"gdp_avg\": gdp_avg\n",
    "    })\n",
    "results_df_na = pd.DataFrame(results_na)\n",
    "\n",
    "# Combine with parameter grid and prepare dataframe for saving\n",
    "precomputed_results_na = param_grid.merge(results_df_na, left_on=\"grid_index\", right_on=\"index\")\n",
    "precomputed_results_na = precomputed_results_na[precomputed_results_na['gdp_avg'].notna()] # remove NaN / failed\n",
    "\n",
    "# Rename columns to match simulation outputs\n",
    "precomputed_results_r_na = precomputed_results_na.copy()\n",
    "precomputed_results_r_na.rename(columns={\n",
    "        'tradable_impact': 'dY_T',\n",
    "        'nontradable_impact': 'dY_N', \n",
    "        'private_impact': 'dK_priv',\n",
    "        'public_impact': 'dK_pub'\n",
    "    }, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "Path(dignad_output_adapt).parent.mkdir(parents=True, exist_ok=True) # create directory if it doesn't already exist\n",
    "precomputed_results_r_na.to_csv(dignad_output_adapt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100fb74f-4a79-44ce-b7ef-93d9be81b866",
   "metadata": {},
   "source": [
    "##### 7. Run DIGNAD pre-simulation (adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef2966-c582-4771-bb11-95f56d34478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating DIGNAD (adaptation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DIGNAD precomputation:  17%|████████▋                                           | 7/42 [06:34<31:51, 54.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB script not executed succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running DIGNAD precomputation:  57%|████████████████████████████▌                     | 24/42 [29:45<30:12, 100.68s/it]"
     ]
    }
   ],
   "source": [
    "# Calibrate DIGNAD (baseline = no adaptation)\n",
    "print('Calibrating DIGNAD (adaptation)')\n",
    "prepare_DIGNAD(THA_calibration_path, adaptation_cost=adaptation_cost, root_dir=root)\n",
    "\n",
    "# Run pre-compuataion\n",
    "results_a = []\n",
    "failure_index_a = []\n",
    "for row in tqdm(param_grid.itertuples(index=False), total=len(param_grid), desc=\"Running DIGNAD precomputation\"):\n",
    "    # Extract shock paramaters\n",
    "    index = row.grid_index\n",
    "    tradable_impact = row.tradable_impact\n",
    "    nontradable_impact = row.nontradable_impact\n",
    "    private_impact = row.private_impact\n",
    "    public_impact = row.public_impact\n",
    "    share_tradable = row.share_tradable\n",
    "    reconstruction_efficiency = row.reconstruction_efficiency\n",
    "    public_debt_premium = row.public_debt_premium\n",
    "\n",
    "    # If shocks are 0 don't run DIGNAD\n",
    "    if tradable_impact == 0 and nontradable_impact == 0 and private_impact == 0 and public_impact == 0:\n",
    "        results_a.append({\n",
    "            \"index\": index,\n",
    "            \"gdp_avg\": 0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Run DIGNAD\n",
    "    gdp_impact, years = run_DIGNAD(sim_start_year, nat_disaster_year, recovery_period, tradable_impact, nontradable_impact,\n",
    "                                    reconstruction_efficiency, public_debt_premium, public_impact, private_impact, share_tradable, root)\n",
    "\n",
    "    if gdp_impact is None:\n",
    "        # Means MatLab failed to execute\n",
    "        failure_index_a.append(index)\n",
    "        gdp_avg = None\n",
    "    else:\n",
    "        t_shock = nat_disaster_year-sim_start_year\n",
    "        gdp_avg = np.mean(gdp_impact[t_shock : t_shock + gdp_avg_years])\n",
    "\n",
    "    results_a.append({\n",
    "        \"index\": index,\n",
    "        \"gdp_avg\": gdp_avg\n",
    "    })\n",
    "results_df_a = pd.DataFrame(results_a)\n",
    "\n",
    "# Combine with parameter grid and prepare dataframe for saving\n",
    "precomputed_results_a = param_grid.merge(results_df_a, left_on=\"grid_index\", right_on=\"index\")\n",
    "precomputed_results_a = precomputed_results_a[precomputed_results_a['gdp_avg'].notna()] # remove NaN / failed\n",
    "\n",
    "# Rename columns to match simulation outputs\n",
    "precomputed_results_r_a = precomputed_results_a.copy()\n",
    "precomputed_results_r_a.rename(columns={\n",
    "        'tradable_impact': 'dY_T',\n",
    "        'nontradable_impact': 'dY_N', \n",
    "        'private_impact': 'dK_priv',\n",
    "        'public_impact': 'dK_pub'\n",
    "    }, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "Path(dignad_output_adapt).parent.mkdir(parents=True, exist_ok=True) # create directory if it doesn't already exist\n",
    "precomputed_results_r_a.to_csv(dignad_output_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad357f-679d-4870-911a-8aff5fa773a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sovereign-risk",
   "language": "python",
   "name": "sovereign-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
