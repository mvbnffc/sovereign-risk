{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fa8e1f-e105-43f8-90b1-42d23de639dd",
   "metadata": {},
   "source": [
    "### Preperation Notebook - Copula Flood Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538a709-1cc7-4d97-85d4-2dda45bab007",
   "metadata": {},
   "source": [
    "\n",
    "This notebook calculates the dependence structure between river basins using a T-Copula and GloFAS discharge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e1e062-e1a0-4ee0-ad16-1e9c8845c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import live code changes in\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t, chi2\n",
    "\n",
    "from sovereign.flood import combine_glofas, extract_discharge_timeseries, fit_gumbel_distribution, calculate_uniform_marginals\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67edb32-ff96-43a9-a631-8f8af6b97968",
   "metadata": {},
   "source": [
    "##### 1. User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f72a6d1-65d2-494e-b757-219136b0269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence analysis parameters\n",
    "start_year = 1979 # start year for discharge data\n",
    "end_year = 2016 # end year for discharge data\n",
    "area_filter = 500 # not considering rivers with upstream areas below 500 km^2\n",
    "n_samples = 100000 # number of copula samples to fit (will be used in subsequent Monte Carlo simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9637f-cec1-4d22-8c6d-9970ae956408",
   "metadata": {},
   "source": [
    "##### 2. Set filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19cdeb9-759e-433b-b737-dcc32e17b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent.parent # find project root\n",
    "glofas_path = os.path.join(root, 'inputs', 'flood', 'dependence', 'glofas')\n",
    "basin_outlets_path = os.path.join(root, 'inputs', 'flood', 'dependence', 'basin_outlets_match.csv') # Lat Lon points at basin outlets\n",
    "copula_samples_path = os.path.join(root, 'outputs', 'flood', 'dependence', 'copulas', 'copula_random_numbers.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00082eaf-d59c-4214-a5ba-3f2951884941",
   "metadata": {},
   "source": [
    "##### 3. Extract Discharge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3113d87f-d34c-4988-832b-d644742017a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloFAS river discharge data and upstream accumulating area data\n",
    "glofas_data = combine_glofas(start_year, end_year, glofas_path, area_filter)\n",
    "# Load the basin outlet file, perform some data checks (to ensure we have valid discharge timeseries at each basin outlet point), and then extract discharge timeseries for each basin\n",
    "basin_outlets = pd.read_csv(basin_outlets_path)\n",
    "# Note to align the two datasets we need to make the following adjustment to lat lons (based on previous trial and error)\n",
    "basin_outlets['Latitude'] = basin_outlets['Latitude'] + 0.05/2\n",
    "basin_outlets['Longitude'] = basin_outlets['Longitude'] - 0.05/2\n",
    "# Extract discharge timeseries\n",
    "basin_timeseries = extract_discharge_timeseries(basin_outlets, glofas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae32b7-8e9d-4ceb-b37c-a37d7b8edd05",
   "metadata": {},
   "source": [
    "##### 4. Fit Gumbel Distribution and Compute Uniform Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a03fc77-85a7-44b6-b1b8-0e46902548ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gumbel distribution using annual maxima\n",
    "gumbel_params, fit_quality = fit_gumbel_distribution(basin_timeseries)\n",
    "# Compute uniform marginals\n",
    "uniform_marginals = calculate_uniform_marginals(basin_timeseries, gumbel_params)\n",
    "\n",
    "# Assign each basin to their L3 (major) river basin (assuming independence across major river basins). 5 total L3 basins\n",
    "marginals = pd.DataFrame(uniform_marginals)\n",
    "l3_basins = basin_outlets.HYBAS_ID_L3.unique()\n",
    "l3_data = {}\n",
    "for basin in l3_basins:\n",
    "    associated_l6_basins = list(basin_outlets[basin_outlets.HYBAS_ID_L3 == basin].HYBAS_ID_L6.unique())\n",
    "    data = marginals[associated_l6_basins]\n",
    "    l3_data[basin] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4196f2-0224-4807-a485-1c5b1cb29595",
   "metadata": {},
   "source": [
    "##### 5. Fit T-Copula and generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf1a36e-30dd-4190-bcc4-f7f4e3962f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samples = {}\n",
    "\n",
    "for basin, data in l3_data.items():\n",
    "    corr_matrix = data.corr().values\n",
    "    mu = np.zeros(len(corr_matrix))\n",
    "    s = chi2.rvs(df=3, size=n_samples)[:, np.newaxis]\n",
    "    Z = np.random.multivariate_normal(mu, corr_matrix, n_samples)\n",
    "    X = np.sqrt(3/s)*Z\n",
    "    U = t.cdf(X, df=3)\n",
    "    t_samples[basin] = pd.DataFrame(U, columns=data.columns)\n",
    "\n",
    "generated_samples = pd.DataFrame()\n",
    "for basin, sample in t_samples.items():\n",
    "    generated_samples = pd.concat([generated_samples, sample], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a079d6ae-41fa-49cf-a147-dfb19d234c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "# Create output directory if it doesn't already exist\n",
    "Path(copula_samples_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "generated_samples.to_parquet(copula_samples_path, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3f2e6-0eea-4c3a-9b85-7fa2a3aa1b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sovereign-risk",
   "language": "python",
   "name": "sovereign-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
