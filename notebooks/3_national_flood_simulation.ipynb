{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d8b2da-7e91-49d6-a78f-100cfe104982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import live code changes in\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sovereign.flood import build_basin_curves, BasinLossCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40514aec-2825-4f5f-a465-391e954997e6",
   "metadata": {},
   "source": [
    "#### Set filepaths and provide data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cd55bf-76ea-4bc3-84c7-3f344c429e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent # find project root\n",
    "risk_basin_path = os.path.join(root, 'outputs', 'flood', 'risk', 'basins', 'risk_basins.csv')\n",
    "copula_path = os.path.join(root, 'outputs', 'flood', 'dependence', 'copulas')\n",
    "risk_data = pd.read_csv(risk_basin_path)\n",
    "# Drop first \"unnamed column\"\n",
    "risk_data = risk_data.iloc[:, 1:]\n",
    "# Add AEP column\n",
    "risk_data['AEP'] = 1 / risk_data['RP']\n",
    "# Add a column converting current prorection level into AEP\n",
    "risk_data['Pr_L_AEP'] = np.where(risk_data['Pr_L'] == 0, 0, 1 / risk_data['Pr_L']) # using numpy where avoids zero division errors\n",
    "risk_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13fe88-dd6d-43e4-a648-9926dcc1c482",
   "metadata": {},
   "source": [
    "#### Build basin loss-probability curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973d52d8-3a12-4eb0-8ac2-e2b051c94ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_curves: dict[int, BasinLossCurve] = build_basin_curves(risk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcfc40-f17d-45e8-9b7e-0a664b19f0b2",
   "metadata": {},
   "source": [
    "#### Run a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780e5444-b0c4-48a3-84e7-ba6b2931f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER CONFIG\n",
    "adaptation_aep = 0.01 # 100-year flood protection\n",
    "n_years = 100 # number of years to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79416c7-84f6-47bd-98fb-3997285bb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare simulation\n",
    "all_sectors = {comp.sector for curve in basin_curves.values() for comp in curve.components} # Find all sectors\n",
    "sector_baseline_losses = {s: np.zeros(n_years) for s in all_sectors}\n",
    "sector_adapted_losses = {s: np.zeros(n_years) for s in all_sectors}\n",
    "gva_sectors = [\"Agriculture\", \"Manufacturing\", \"Service\"]\n",
    "cap_sectors = [\"Public\", \"Private\"]\n",
    "basin_ids = list(basin_curves.keys())\n",
    "# Load precomputed copula basin dependence simulations\n",
    "t_random_numbers = pd.read_parquet(os.path.join(copula_path, \"t_random_numbers.parquet.gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1614c1a1-73ad-4392-81da-a06e791a57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 130.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run a simulation assuming complete independence between basins\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "for t in tqdm(range(n_years)):\n",
    "    sector_year_baseline = {s: 0.0 for s in all_sectors}\n",
    "    sector_year_adapted = {s: 0.0 for s in all_sectors}\n",
    "\n",
    "    for basin_id in basin_ids:\n",
    "        curve = basin_curves[basin_id]\n",
    "        aep_event = rng.uniform(0.0, 1.0)\n",
    "\n",
    "        for s  in all_sectors:\n",
    "            bl = curve.loss_at_event_aep(aep_event, sector=s)\n",
    "            ad = curve.loss_at_event_aep(aep_event, scenario=\"adaptation\", adapted_protection_aep=adaptation_aep, sector=s)\n",
    "            sector_year_baseline[s] += bl\n",
    "            sector_year_adapted[s] += ad\n",
    "    \n",
    "    for s in all_sectors:\n",
    "        sector_baseline_losses[s][t] = sector_year_baseline[s]\n",
    "        sector_adapted_losses[s][t] = sector_year_adapted[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd6cd06-2e62-4a65-9544-404821fb76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GVA AAL baseline: 4022474201.860404\n",
      "GVA AAL adapted : 1679064755.8401444\n",
      "Cap AAL baseline: 12901749155.328045\n",
      "Cap AAL adapted : 6461037134.455752\n",
      "GVA AAL avoided : 2343409446.02026\n",
      "Cap AAL avoided : 6440712020.8722925\n"
     ]
    }
   ],
   "source": [
    "# GVA losses (sum of GVA sectors)\n",
    "gva_baseline_losses = sum(sector_baseline_losses[s] for s in gva_sectors)\n",
    "gva_adapted_losses  = sum(sector_adapted_losses[s]  for s in gva_sectors)\n",
    "\n",
    "# Capital stock losses (sum of capital sectors)\n",
    "cap_baseline_losses = sum(sector_baseline_losses[s] for s in cap_sectors)\n",
    "cap_adapted_losses  = sum(sector_adapted_losses[s]  for s in cap_sectors)\n",
    "\n",
    "print(\"GVA AAL baseline:\", gva_baseline_losses.mean())\n",
    "print(\"GVA AAL adapted :\", gva_adapted_losses.mean())\n",
    "print(\"Cap AAL baseline:\", cap_baseline_losses.mean())\n",
    "print(\"Cap AAL adapted :\", cap_adapted_losses.mean())\n",
    "\n",
    "print(\"GVA AAL avoided :\", gva_baseline_losses.mean() - gva_adapted_losses.mean())\n",
    "print(\"Cap AAL avoided :\", cap_baseline_losses.mean() - cap_adapted_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf885b8-473b-43ea-b7b3-5bbc67e2b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 129.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run a simulation with copula dependence between basins\n",
    "for t in tqdm(range(n_years)):\n",
    "    sector_year_baseline = {s: 0.0 for s in all_sectors}\n",
    "    sector_year_adapted = {s: 0.0 for s in all_sectors}\n",
    "    random_ns = t_random_numbers.loc[t] # extract random numbers for year t\n",
    "\n",
    "    for basin_id in basin_ids:\n",
    "        # TEMP DEBUG (need to re-run copulas as some basins not included)\n",
    "        basin_str = str(int(basin_id))\n",
    "        if basin_str not in random_ns:\n",
    "            continue # skip\n",
    "        curve = basin_curves[basin_id]\n",
    "        aep_event = 1-random_ns[str(int(basin_id))] # may also be 1 - r need to check\n",
    "\n",
    "        for s  in all_sectors:\n",
    "            bl = curve.loss_at_event_aep(aep_event, sector=s)\n",
    "            ad = curve.loss_at_event_aep(aep_event, scenario=\"adaptation\", adapted_protection_aep=adaptation_aep, sector=s)\n",
    "            sector_year_baseline[s] += bl\n",
    "            sector_year_adapted[s] += ad\n",
    "    \n",
    "    for s in all_sectors:\n",
    "        sector_baseline_losses[s][t] = sector_year_baseline[s]\n",
    "        sector_adapted_losses[s][t] = sector_year_adapted[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecbd473e-58ec-4082-933f-f1beb8aae4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GVA AAL baseline: 2725590448.771812\n",
      "GVA AAL adapted : 1318025911.3015254\n",
      "Cap AAL baseline: 9636699858.38246\n",
      "Cap AAL adapted : 5027899503.288624\n",
      "GVA AAL avoided : 1407564537.4702866\n",
      "Cap AAL avoided : 4608800355.093836\n"
     ]
    }
   ],
   "source": [
    "# GVA losses (sum of GVA sectors)\n",
    "gva_baseline_losses = sum(sector_baseline_losses[s] for s in gva_sectors)\n",
    "gva_adapted_losses  = sum(sector_adapted_losses[s]  for s in gva_sectors)\n",
    "\n",
    "# Capital stock losses (sum of capital sectors)\n",
    "cap_baseline_losses = sum(sector_baseline_losses[s] for s in cap_sectors)\n",
    "cap_adapted_losses  = sum(sector_adapted_losses[s]  for s in cap_sectors)\n",
    "\n",
    "print(\"GVA AAL baseline:\", gva_baseline_losses.mean())\n",
    "print(\"GVA AAL adapted :\", gva_adapted_losses.mean())\n",
    "print(\"Cap AAL baseline:\", cap_baseline_losses.mean())\n",
    "print(\"Cap AAL adapted :\", cap_adapted_losses.mean())\n",
    "\n",
    "print(\"GVA AAL avoided :\", gva_baseline_losses.mean() - gva_adapted_losses.mean())\n",
    "print(\"Cap AAL avoided :\", cap_baseline_losses.mean() - cap_adapted_losses.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695420b9-9150-4414-af2b-04879b7c38c1",
   "metadata": {},
   "source": [
    "#### DIGNAD Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d4fa43-0103-4b21-929e-f051c7f2bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User config and PREP\n",
    "n_years = 10000\n",
    "GDP = 500e9\n",
    "# National GVA figures from DOSE\n",
    "agr_GVA = 42880325598\n",
    "man_GVA = 162659433017\n",
    "ser_GVA = 316647741231\n",
    "\n",
    "adaptation_aep = 0.01\n",
    "TRADABLE_SHARES = {\n",
    "    \"Agriculture\": 1.0,\n",
    "    \"Manufacturing\": 0.7,\n",
    "    \"Service\": 0.5,\n",
    "}\n",
    "PRIVATE_TRADABLE_CAP_SHARE = 50 # assume % share of private capital that belongs to tradable sectors\n",
    "\n",
    "# Calculate tradable and nontradable output based on DOSE numbers and sector plits\n",
    "tradable_output_baseline = (\n",
    "    agr_GVA * TRADABLE_SHARES[\"Agriculture\"] +\n",
    "    man_GVA * TRADABLE_SHARES[\"Manufacturing\"] +\n",
    "    ser_GVA * TRADABLE_SHARES[\"Service\"]\n",
    ")\n",
    "\n",
    "nontrad_output_baseline = (\n",
    "    agr_GVA * (1 - TRADABLE_SHARES[\"Agriculture\"]) +\n",
    "    man_GVA * (1 - TRADABLE_SHARES[\"Manufacturing\"]) +\n",
    "    ser_GVA * (1 - TRADABLE_SHARES[\"Service\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b8b86d-61c7-43a3-9940-14c072db6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sector list and storage\n",
    "# discover all sectors from the curves\n",
    "all_sectors = {c.sector for curve in basin_curves.values() for c in curve.components}\n",
    "gva_sectors = [\"Agriculture\", \"Manufacturing\", \"Service\"]\n",
    "cap_sectors = [\"Public\", \"Private\"]\n",
    "# per-sector annual losses (monetary)\n",
    "sector_baseline_losses = {s: np.zeros(n_years) for s in all_sectors}\n",
    "sector_adapted_losses  = {s: np.zeros(n_years) for s in all_sectors}\n",
    "# DIGNAD aggregate series (per year)\n",
    "trad_output_loss_pct_baseline    = np.zeros(n_years)\n",
    "trad_output_loss_pct_adapted     = np.zeros(n_years)\n",
    "nontrad_output_loss_pct_baseline = np.zeros(n_years)\n",
    "nontrad_output_loss_pct_adapted  = np.zeros(n_years)\n",
    "private_cap_damage_pct_gdp_baseline  = np.zeros(n_years)\n",
    "private_cap_damage_pct_gdp_adapted   = np.zeros(n_years)\n",
    "public_cap_damage_pct_gdp_baseline   = np.zeros(n_years)\n",
    "public_cap_damage_pct_gdp_adapted    = np.zeros(n_years)\n",
    "tradable_cap_damage_share_baseline   = np.zeros(n_years)\n",
    "tradable_cap_damage_share_adapted    = np.zeros(n_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7897e1-8445-429a-a2e1-df58ae799456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:18<00:00, 126.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(n_years)):\n",
    "    # sector totals for this simulated year\n",
    "    sector_year_baseline = {s: 0.0 for s in all_sectors}\n",
    "    sector_year_adapted  = {s: 0.0 for s in all_sectors}\n",
    "    random_ns = t_random_numbers.loc[t] # extract random numbers for year t\n",
    "\n",
    "    for basin_id in basin_ids:\n",
    "        # TEMP DEBUG (need to re-run copulas as some basins not included)\n",
    "        basin_str = str(int(basin_id))\n",
    "        if basin_str not in random_ns:\n",
    "            continue # skip\n",
    "        curve = basin_curves[basin_id]\n",
    "        aep_event = 1-random_ns[str(int(basin_id))] # may also be 1 - r need to check\n",
    "\n",
    "        for s in all_sectors:\n",
    "            # baseline\n",
    "            bl = curve.loss_at_event_aep(\n",
    "                aep_event,\n",
    "                scenario=\"baseline\",\n",
    "                sector=s,\n",
    "            )\n",
    "            # adaptation\n",
    "            ad = curve.loss_at_event_aep(\n",
    "                aep_event,\n",
    "                scenario=\"adaptation\",\n",
    "                adapted_protection_aep=adaptation_aep,\n",
    "                sector=s,\n",
    "            )\n",
    "            sector_year_baseline[s] += bl\n",
    "            sector_year_adapted[s]  += ad\n",
    "\n",
    "    # store per-sector time series\n",
    "    for s in all_sectors:\n",
    "        sector_baseline_losses[s][t] = sector_year_baseline[s]\n",
    "        sector_adapted_losses[s][t]  = sector_year_adapted[s]\n",
    "\n",
    "    # ---- MAP TO DIGNAD AGGREGATES (BASELINE) ----\n",
    "    ag_b   = sector_year_baseline.get(\"Agriculture\", 0.0)\n",
    "    man_b  = sector_year_baseline.get(\"Manufacturing\", 0.0)\n",
    "    serv_b = sector_year_baseline.get(\"Service\", 0.0)\n",
    "    priv_b = sector_year_baseline.get(\"Private\", 0.0)\n",
    "    pub_b  = sector_year_baseline.get(\"Public\", 0.0)\n",
    "\n",
    "    trad_out_b = (\n",
    "        ag_b  * TRADABLE_SHARES[\"Agriculture\"] +\n",
    "        man_b * TRADABLE_SHARES[\"Manufacturing\"] +\n",
    "        serv_b* TRADABLE_SHARES[\"Service\"]\n",
    "    )\n",
    "    nontrad_out_b = (\n",
    "        ag_b  * (1 - TRADABLE_SHARES[\"Agriculture\"]) +\n",
    "        man_b * (1 - TRADABLE_SHARES[\"Manufacturing\"]) +\n",
    "        serv_b* (1 - TRADABLE_SHARES[\"Service\"])\n",
    "    )\n",
    "\n",
    "    trad_output_loss_pct_baseline[t]    = 100 * trad_out_b    / tradable_output_baseline\n",
    "    nontrad_output_loss_pct_baseline[t] = 100 * nontrad_out_b / nontrad_output_baseline\n",
    "    private_cap_damage_pct_gdp_baseline[t]  = 100 * priv_b / GDP\n",
    "    public_cap_damage_pct_gdp_baseline[t]   = 100 * pub_b  / GDP\n",
    "\n",
    "    if priv_b > 0:\n",
    "        tradable_cap_damage_share_baseline[t] = PRIVATE_TRADABLE_CAP_SHARE\n",
    "    else:\n",
    "        tradable_cap_damage_share_baseline[t] = np.nan  # or 0.0\n",
    "\n",
    "    # ---- MAP TO DIGNAD AGGREGATES (ADAPTED) ----\n",
    "    ag_a   = sector_year_adapted.get(\"Agriculture\", 0.0)\n",
    "    man_a  = sector_year_adapted.get(\"Manufacturing\", 0.0)\n",
    "    serv_a = sector_year_adapted.get(\"Service\", 0.0)\n",
    "    priv_a = sector_year_adapted.get(\"Private\", 0.0)\n",
    "    pub_a  = sector_year_adapted.get(\"Public\", 0.0)\n",
    "\n",
    "    trad_out_a = (\n",
    "        ag_a  * TRADABLE_SHARES[\"Agriculture\"] +\n",
    "        man_a * TRADABLE_SHARES[\"Manufacturing\"] +\n",
    "        serv_a* TRADABLE_SHARES[\"Service\"]\n",
    "    )\n",
    "    nontrad_out_a = (\n",
    "        ag_a  * (1 - TRADABLE_SHARES[\"Agriculture\"]) +\n",
    "        man_a * (1 - TRADABLE_SHARES[\"Manufacturing\"]) +\n",
    "        serv_a* (1 - TRADABLE_SHARES[\"Service\"])\n",
    "    )\n",
    "\n",
    "    trad_output_loss_pct_adapted[t]    = 100 * trad_out_a    / tradable_output_baseline\n",
    "    nontrad_output_loss_pct_adapted[t] = 100 * nontrad_out_a / nontrad_output_baseline\n",
    "    private_cap_damage_pct_gdp_adapted[t]  = 100 * priv_a / GDP\n",
    "    public_cap_damage_pct_gdp_adapted[t]   = 100 * pub_a  / GDP\n",
    "\n",
    "    if priv_a > 0:\n",
    "        tradable_cap_damage_share_adapted[t] = PRIVATE_TRADABLE_CAP_SHARE\n",
    "    else:\n",
    "        tradable_cap_damage_share_adapted[t] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c366c955-dd82-462e-aee2-942ca520599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shocks = pd.DataFrame({\n",
    "    \"year_index\": np.arange(n_years),\n",
    "    \"dY_T\": trad_output_loss_pct_baseline,       # tradable output loss (% trad output)\n",
    "    \"dY_N\": nontrad_output_loss_pct_baseline,    # non-trad output loss (% non-trad output)\n",
    "    \"dK_priv\": private_cap_damage_pct_gdp_baseline,  # % GDP\n",
    "    \"dK_pub\":  public_cap_damage_pct_gdp_baseline,   # % GDP\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3758e975-86eb-4730-84a0-78495566f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_index</th>\n",
       "      <th>dY_T</th>\n",
       "      <th>dY_N</th>\n",
       "      <th>dK_priv</th>\n",
       "      <th>dK_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092431</td>\n",
       "      <td>0.036944</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.051653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464417</td>\n",
       "      <td>0.240349</td>\n",
       "      <td>0.618818</td>\n",
       "      <td>0.282756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.362882</td>\n",
       "      <td>0.274927</td>\n",
       "      <td>0.683439</td>\n",
       "      <td>0.492005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>0.078273</td>\n",
       "      <td>0.042824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>4.157965</td>\n",
       "      <td>3.991120</td>\n",
       "      <td>12.652502</td>\n",
       "      <td>4.334972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>0.688659</td>\n",
       "      <td>2.463884</td>\n",
       "      <td>1.182258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_index      dY_T      dY_N    dK_priv    dK_pub\n",
       "0              0  0.092431  0.036944   0.091922  0.051653\n",
       "1              1  0.464417  0.240349   0.618818  0.282756\n",
       "2              2  0.362882  0.274927   0.683439  0.492005\n",
       "3              3  0.000000  0.000000   0.000000  0.000000\n",
       "4              4  0.000000  0.000000   0.000000  0.000000\n",
       "...          ...       ...       ...        ...       ...\n",
       "9995        9995  0.000000  0.000000   0.000000  0.000000\n",
       "9996        9996  0.032671  0.021055   0.078273  0.042824\n",
       "9997        9997  4.157965  3.991120  12.652502  4.334972\n",
       "9998        9998  0.862400  0.688659   2.463884  1.182258\n",
       "9999        9999  0.000000  0.000000   0.000000  0.000000\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fd20f717-c7bb-48e1-aab0-e2a06f97627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dY_T       22.325263\n",
       "dY_N       25.950726\n",
       "dK_priv    42.398185\n",
       "dK_pub     15.123066\n",
       "Name: 0.999, dtype: float64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"dY_T\", \"dY_N\", \"dK_priv\", \"dK_pub\"]\n",
    "q = 0.999  # 99th percentile thresholds\n",
    "thresholds = shocks[cols].quantile(q)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a9a8620b-97a8-4262-9e28-01e30fd859d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_index</th>\n",
       "      <th>dY_T</th>\n",
       "      <th>dY_N</th>\n",
       "      <th>dK_priv</th>\n",
       "      <th>dK_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1073</td>\n",
       "      <td>23.984686</td>\n",
       "      <td>27.753205</td>\n",
       "      <td>45.189882</td>\n",
       "      <td>16.106309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1104</td>\n",
       "      <td>23.109953</td>\n",
       "      <td>26.380166</td>\n",
       "      <td>43.596121</td>\n",
       "      <td>15.422342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>3872</td>\n",
       "      <td>25.885314</td>\n",
       "      <td>29.045270</td>\n",
       "      <td>47.940787</td>\n",
       "      <td>17.744415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>4089</td>\n",
       "      <td>22.702249</td>\n",
       "      <td>26.045535</td>\n",
       "      <td>42.428922</td>\n",
       "      <td>15.289534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>4335</td>\n",
       "      <td>25.138196</td>\n",
       "      <td>28.581100</td>\n",
       "      <td>47.093847</td>\n",
       "      <td>17.073515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>5632</td>\n",
       "      <td>25.013147</td>\n",
       "      <td>28.334446</td>\n",
       "      <td>45.609074</td>\n",
       "      <td>16.569101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>7520</td>\n",
       "      <td>23.534317</td>\n",
       "      <td>27.233926</td>\n",
       "      <td>44.418311</td>\n",
       "      <td>15.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8665</th>\n",
       "      <td>8665</td>\n",
       "      <td>23.481041</td>\n",
       "      <td>26.775625</td>\n",
       "      <td>43.990406</td>\n",
       "      <td>15.912869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_index       dY_T       dY_N    dK_priv     dK_pub\n",
       "1073        1073  23.984686  27.753205  45.189882  16.106309\n",
       "1104        1104  23.109953  26.380166  43.596121  15.422342\n",
       "3872        3872  25.885314  29.045270  47.940787  17.744415\n",
       "4089        4089  22.702249  26.045535  42.428922  15.289534\n",
       "4335        4335  25.138196  28.581100  47.093847  17.073515\n",
       "5632        5632  25.013147  28.334446  45.609074  16.569101\n",
       "7520        7520  23.534317  27.233926  44.418311  15.961600\n",
       "8665        8665  23.481041  26.775625  43.990406  15.912869"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.ones(len(shocks), dtype=bool)\n",
    "for c in cols:\n",
    "    mask &= shocks[c] >= thresholds[c]\n",
    "\n",
    "extreme_all_high = shocks[mask]\n",
    "extreme_all_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891e0b2-6a8a-4020-a7b0-ccf00fe856cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sovereign-risk",
   "language": "python",
   "name": "sovereign-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
