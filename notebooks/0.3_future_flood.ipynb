{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "034eee8e-577a-4ff8-80fb-f15ae72f0166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import live code changes in\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterstats import zonal_stats\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sovereign.utils import df_to_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda1281-3434-4c9b-a036-db117e128a34",
   "metadata": {},
   "source": [
    "#### Set filepaths and data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053a425b-1409-48f6-b234-035c9262e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent # find project root\n",
    "future_flood_path = Path(os.path.join(root, 'outputs', 'flood', 'future', 'results.parquet.gzip'))\n",
    "BASIN_SHP = Path(os.path.join(root, 'inputs', 'boundaries', 'basins', 'BA_THA_lev06.shp'))\n",
    "# where to save rasters\n",
    "RASTER_DIR = Path(os.path.join(root, 'outputs', 'flood', 'future', 'maps'))\n",
    "# where to save the basin RP shifts\n",
    "FUTURE_BASINS = Path(os.path.join(root, 'outputs', 'flood', 'future', 'basin_rp_shifts.csv'))\n",
    "# USER CONFIG\n",
    "RPS = [10, 20, 50, 75, 100, 200, 500] # what are the retrun periods we are using\n",
    "EPOCHS = ['2030', '2040', '2050', '2060', '2070'] # what future epochs are we interested in?\n",
    "SCENARIOS = ['ssp126', 'ssp370', 'ssp585'] # what climate scenarios are we intersted in?\n",
    "# Relevant columns from the future flood dataframe\n",
    "VALUE_COL = 'adjusted_return_period'\n",
    "HYDRO_COL = 'hydro'\n",
    "CLIM_COL = 'climate'\n",
    "SCEN_COL = 'climate_scenario'\n",
    "EPOCH_COL = 'period'\n",
    "RP_COL = 'return_period'\n",
    "LAT_COL = 'latitude'\n",
    "LON_COL = 'longitude'\n",
    "# Info for basin columns\n",
    "BASIN_ID_COL = \"HYBAS_ID\"\n",
    "geometry_col = \"geometry\"\n",
    "NEW_BASIN_ID_COL = \"HB_L6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a62fc09d-015f-4882-9331-44c818d0b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and clean the data\n",
    "future_df = pd.read_parquet(future_flood_path)\n",
    "# Do some cleaning of the dataframe\n",
    "future_df['noext'] = future_df['model'].str.replace('.nc', '', regex=False)\n",
    "# split by '_'\n",
    "parts = future_df['noext'].str.split('_', expand=True)\n",
    "future_df[HYDRO_COL] = parts[2] # add a specific hydro model column\n",
    "future_df[CLIM_COL] = parts[3] # add a specific climate model column\n",
    "future_df = future_df.drop(columns=['noext']) # clean up\n",
    "basins = gpd.read_file(BASIN_SHP)\n",
    "basins = basins[[BASIN_ID_COL, geometry_col]]\n",
    "basins = basins.rename(columns={BASIN_ID_COL: NEW_BASIN_ID_COL})\n",
    "# Create raster directory if it doesn't already exoist\n",
    "RASTER_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db65dde-7b25-4817-ad7a-591fe012bf07",
   "metadata": {},
   "source": [
    "#### Create ISIMIP future RP change rasters (from dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1bac6e0-9352-431f-a133-e2cdd1ea4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique hydro model and climate model pairs in the dataframe\n",
    "model_pairs = (\n",
    "    future_df[[HYDRO_COL, CLIM_COL]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "model_pairs = list(model_pairs) # Make it a list\n",
    "\n",
    "# Loop over all combinations and rasterize\n",
    "for hydro, clim in model_pairs:\n",
    "    for scen in SCENARIOS:\n",
    "        for epoch in EPOCHS:\n",
    "            for rp in RPS:               \n",
    "                # Set output filepath\n",
    "                out_name = f\"{hydro}_{clim}_{scen}_{epoch}_rp{rp:03d}.tif\"\n",
    "                out_path = Path(os.path.join(RASTER_DIR, out_name))\n",
    "                # Skip if file already exists\n",
    "                if out_path.exists():\n",
    "                    continue\n",
    "                # Extract dataframe subset\n",
    "                sub = future_df[(future_df[HYDRO_COL] == hydro) & (future_df[CLIM_COL] == clim) & (future_df[SCEN_COL] == scen) \n",
    "                    & (future_df[EPOCH_COL] == epoch) & (future_df[RP_COL] == rp)]\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                # Convert to raster\n",
    "                df_to_raster(sub, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4742e-457b-4c95-a664-f4b078277c4d",
   "metadata": {},
   "source": [
    "#### Loop over the rasters and calculate basin return period change averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf8be23-e749-43a7-9ee0-8c0cd08cd73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Zonal Stats: 100%|███████████████████████████████████████████████████████| 3150/3150 [2:31:58<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "records = [] # empty list to save results to\n",
    "# Loop over all rasters\n",
    "for tif_path in tqdm(sorted(RASTER_DIR.glob(\"*.tif\")), desc=\"Running Zonal Stats\"):\n",
    "    stem = tif_path.stem  # e.g. \"cwatm_gfdl-esm4_ssp126_2030_rp010\"\n",
    "    parts = stem.split(\"_\")\n",
    "    if len(parts) != 5:\n",
    "        print(f\"Skipping unexpected filename: {stem}\")\n",
    "        continue\n",
    "\n",
    "    hydro, clim, scen, epoch, rp_str = parts\n",
    "    rp = int(rp_str.replace(\"rp\", \"\"))\n",
    "\n",
    "    # Zonal stats: mean per basin\n",
    "    zs = zonal_stats(\n",
    "        basins,\n",
    "        tif_path,\n",
    "        stats=[\"mean\"],\n",
    "        nodata=-9999,\n",
    "        all_touched=True   # calculate stats on any cells that touch region\n",
    "    )\n",
    "    means = [z[\"mean\"] for z in zs]\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        NEW_BASIN_ID_COL: basins[NEW_BASIN_ID_COL].values,\n",
    "        HYDRO_COL: hydro,\n",
    "        CLIM_COL: clim,\n",
    "        SCEN_COL: scen,\n",
    "        EPOCH_COL: int(epoch),\n",
    "        RP_COL: rp,\n",
    "        \"basin_mean_value\": means,\n",
    "    })\n",
    "\n",
    "    records.append(tmp)\n",
    "\n",
    "# Combine everything\n",
    "future_rp_shifts = pd.concat(records, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cc7ca-58be-4d34-838a-1d43d7008fa7",
   "metadata": {},
   "source": [
    "#### Create Basin Return Period Change Dataframe and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f58d70f3-768b-4d23-9fdc-7650e4cf9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark.DESKTOP-UFHIN6T\\AppData\\Local\\Temp\\ipykernel_14924\\2186682106.py:2: FutureWarning: The provided callable <function mean at 0x0000018CA720E1F0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  grouped = (future_rp_shifts.groupby([NEW_BASIN_ID_COL, HYDRO_COL, SCEN_COL, EPOCH_COL, RP_COL])\n"
     ]
    }
   ],
   "source": [
    "# Calculate stats across climate models for each hydro model and scenario:epoch:rp combination\n",
    "grouped = (future_rp_shifts.groupby([NEW_BASIN_ID_COL, HYDRO_COL, SCEN_COL, EPOCH_COL, RP_COL])\n",
    "    .agg(q90=(\"basin_mean_value\", lambda x: x.quantile(0.1)),\n",
    "        q50=(\"basin_mean_value\", lambda x: x.quantile(0.50)),\n",
    "        q10=(\"basin_mean_value\", lambda x: x.quantile(0.9)),\n",
    "        mean=(\"basin_mean_value\", np.mean)))\n",
    "grouped.columns.name = \"stat\"\n",
    "# Convert to stacked dataframe for saving\n",
    "long_stats = (\n",
    "    grouped\n",
    "    .stack()\n",
    "    .reset_index(name=\"new_rp_value\")\n",
    ")\n",
    "# Save to CSV\n",
    "long_stats.to_csv(os.path.join(root, 'outputs', 'flood', 'future', 'basin_rp_shifts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c64be-222a-47bd-bda9-34e0e660ac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sovereign-risk",
   "language": "python",
   "name": "sovereign-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
